#!/usr/bin/env python3
"""
Email Task Manager Email Intelligence Agent
Advanced email pattern analysis, sender classification, and smart filtering
"""

import os
import re
import json
import sqlite3
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple
from pathlib import Path
from collections import defaultdict, Counter

class EmailTaskIntelligenceEngine:
    """Advanced email analysis and intelligence for Email Task Manager"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.backend_path = self.project_root / "backend"
        self.database_path = self.backend_path / "instance" / "email_task_manager.db"
        
        self.analysis_results = {
            'sender_analysis': [],
            'pattern_detection': [],
            'smart_filters': [],
            'productivity_insights': [],
            'categorization_rules': []
        }
        
        # Email patterns for analysis
        self.patterns = {
            'urgent_keywords': ['urgent', 'asap', 'immediate', 'critical', 'emergency'],
            'meeting_keywords': ['meeting', 'call', 'conference', 'zoom', 'teams'],
            'action_keywords': ['action', 'todo', 'task', 'deadline', 'due'],
            'automated_indicators': ['noreply', 'no-reply', 'automated', 'system', 'notification']
        }
    
    def run_complete_analysis(self) -> Dict[str, Any]:
        """Run comprehensive email intelligence analysis"""
        print("ðŸ§  Starting Email Intelligence Analysis...")
        
        # Core analysis modules
        self._analyze_sender_patterns()
        self._detect_email_patterns()
        self._create_smart_filters()
        self._generate_productivity_insights()
        self._build_categorization_system()
        
        # Create intelligence tools
        self._create_analysis_tools()
        self._create_recommendation_engine()
        
        return self._generate_intelligence_report()
    
    def _analyze_sender_patterns(self):
        """Analyze sender behavior patterns"""
        print("ðŸ‘¤ Analyzing sender patterns...")
        
        sender_analyzer = """#!/usr/bin/env python3
\"\"\"
Sender Pattern Analyzer
Generated by Email Intelligence Agent
\"\"\"

import sqlite3
import json
from datetime import datetime, timedelta
from collections import Counter, defaultdict
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from backend import create_app, db
from backend.models.email import Email
from backend.models.task import Task

class SenderAnalyzer:
    def __init__(self):
        self.app = create_app()
    
    def analyze_sender_patterns(self, user_id: int, days: int = 30) -> Dict[str, Any]:
        \"\"\"Analyze sender patterns for a user\"\"\"
        with self.app.app_context():
            cutoff_date = datetime.now() - timedelta(days=days)
            
            emails = Email.query.filter(
                Email.user_id == user_id,
                Email.received_at >= cutoff_date
            ).all()
            
            analysis = {
                'sender_frequency': Counter(),
                'sender_task_generation': defaultdict(int),
                'sender_response_patterns': defaultdict(list),
                'automation_detection': [],
                'vip_senders': []
            }
            
            # Analyze each email
            for email in emails:
                sender_email = email.sender_email or 'unknown'
                analysis['sender_frequency'][sender_email] += 1
                
                # Check if sender generated tasks
                tasks = Task.query.filter_by(email_id=email.id).all()
                if tasks:
                    analysis['sender_task_generation'][sender_email] += len(tasks)
                
                # Detect automated emails
                if self._is_automated_email(email):
                    analysis['automation_detection'].append(sender_email)
            
            # Identify VIP senders (high frequency + task generation)
            for sender, freq in analysis['sender_frequency'].most_common(10):
                task_count = analysis['sender_task_generation'][sender]
                if freq > 5 and task_count > 0:
                    analysis['vip_senders'].append({
                        'sender': sender,
                        'frequency': freq,
                        'task_generation': task_count,
                        'importance_score': freq * 0.3 + task_count * 0.7
                    })
            
            return analysis
    
    def _is_automated_email(self, email: Email) -> bool:
        \"\"\"Detect if email is automated\"\"\"
        automated_indicators = ['noreply', 'no-reply', 'automated', 'system']
        sender_lower = (email.sender_email or '').lower()
        
        return any(indicator in sender_lower for indicator in automated_indicators)
    
    def generate_sender_insights(self, user_id: int) -> List[str]:
        \"\"\"Generate actionable sender insights\"\"\"
        analysis = self.analyze_sender_patterns(user_id)
        insights = []
        
        # Top senders insight
        if analysis['sender_frequency']:
            top_sender = analysis['sender_frequency'].most_common(1)[0]
            insights.append(f"Most frequent sender: {top_sender[0]} ({top_sender[1]} emails)")
        
        # Task generation insight
        top_task_generators = sorted(
            analysis['sender_task_generation'].items(),
            key=lambda x: x[1],
            reverse=True
        )[:3]
        
        if top_task_generators:
            insights.append(f"Top task generators: {[s[0] for s in top_task_generators]}")
        
        # Automation insight
        auto_count = len(set(analysis['automation_detection']))
        if auto_count > 0:
            insights.append(f"Detected {auto_count} automated email sources")
        
        return insights

def main():
    import argparse
    parser = argparse.ArgumentParser(description='Sender Pattern Analyzer')
    parser.add_argument('user_id', type=int, help='User ID to analyze')
    parser.add_argument('--days', type=int, default=30, help='Days to analyze')
    parser.add_argument('--insights', action='store_true', help='Generate insights')
    
    args = parser.parse_args()
    
    analyzer = SenderAnalyzer()
    
    if args.insights:
        insights = analyzer.generate_sender_insights(args.user_id)
        print("Sender Insights:")
        for insight in insights:
            print(f"â€¢ {insight}")
    else:
        analysis = analyzer.analyze_sender_patterns(args.user_id, args.days)
        print(json.dumps(analysis, indent=2, default=str))

if __name__ == "__main__":
    main()
"""
        
        # Create intelligence directory
        intel_dir = self.backend_path / "intelligence"
        intel_dir.mkdir(exist_ok=True)
        
        sender_analyzer_file = intel_dir / "sender_analyzer.py"
        with open(sender_analyzer_file, 'w') as f:
            f.write(sender_analyzer)
        
        try:
            os.chmod(sender_analyzer_file, 0o755)
        except:
            pass
        
        self.analysis_results['sender_analysis'].append({
            'type': 'Sender Pattern Analyzer',
            'file': str(sender_analyzer_file),
            'features': 'Sender frequency, task generation analysis, VIP detection, automation detection',
            'usage': 'python sender_analyzer.py user_id --insights'
        })
    
    def _detect_email_patterns(self):
        """Detect email content patterns"""
        print("ðŸ” Detecting email patterns...")
        
        pattern_detector = """#!/usr/bin/env python3
\"\"\"
Email Pattern Detection Engine
Generated by Email Intelligence Agent
\"\"\"

import re
import json
from datetime import datetime, timedelta
from collections import defaultdict
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from backend import create_app, db
from backend.models.email import Email

class PatternDetector:
    def __init__(self):
        self.app = create_app()
        self.patterns = {
            'urgent': r'\\b(urgent|asap|immediate|critical|emergency)\\b',
            'meeting': r'\\b(meeting|call|conference|zoom|teams|skype)\\b',
            'deadline': r'\\b(deadline|due|expires?|by \\d+)\\b',
            'question': r'\\?|can you|could you|would you|please',
            'action': r'\\b(action|todo|task|complete|finish)\\b'
        }
    
    def detect_patterns(self, user_id: int, days: int = 30) -> Dict[str, Any]:
        \"\"\"Detect patterns in user's emails\"\"\"
        with self.app.app_context():
            cutoff_date = datetime.now() - timedelta(days=days)
            
            emails = Email.query.filter(
                Email.user_id == user_id,
                Email.received_at >= cutoff_date
            ).all()
            
            pattern_matches = defaultdict(list)
            hourly_distribution = defaultdict(int)
            subject_patterns = defaultdict(int)
            
            for email in emails:
                # Analyze content patterns
                content = (email.subject + ' ' + (email.body or '')).lower()
                
                for pattern_name, pattern_regex in self.patterns.items():
                    if re.search(pattern_regex, content, re.IGNORECASE):
                        pattern_matches[pattern_name].append({
                            'email_id': email.id,
                            'sender': email.sender_email,
                            'subject': email.subject,
                            'received_at': email.received_at.isoformat()
                        })
                
                # Analyze timing patterns
                if email.received_at:
                    hour = email.received_at.hour
                    hourly_distribution[hour] += 1
                
                # Analyze subject patterns
                if email.subject:
                    # Extract subject prefixes (e.g., "RE:", "FWD:")
                    prefix_match = re.match(r'^(RE|FWD|FW):', email.subject, re.IGNORECASE)
                    if prefix_match:
                        subject_patterns[prefix_match.group(1).upper()] += 1
                    else:
                        subject_patterns['ORIGINAL'] += 1
            
            return {
                'pattern_matches': dict(pattern_matches),
                'hourly_distribution': dict(hourly_distribution),
                'subject_patterns': dict(subject_patterns),
                'analysis_period': f"{days} days",
                'total_emails': len(emails)
            }
    
    def get_productivity_hours(self, hourly_dist: Dict[int, int]) -> List[int]:
        \"\"\"Identify peak email hours\"\"\"
        if not hourly_dist:
            return []
        
        # Find top 3 hours with most emails
        sorted_hours = sorted(hourly_dist.items(), key=lambda x: x[1], reverse=True)
        return [hour for hour, count in sorted_hours[:3]]
    
    def generate_pattern_insights(self, user_id: int) -> List[str]:
        \"\"\"Generate pattern-based insights\"\"\"
        patterns = self.detect_patterns(user_id)
        insights = []
        
        # Pattern frequency insights
        for pattern, matches in patterns['pattern_matches'].items():
            if len(matches) > 5:
                insights.append(f"High {pattern} pattern: {len(matches)} emails")
        
        # Timing insights
        peak_hours = self.get_productivity_hours(patterns['hourly_distribution'])
        if peak_hours:
            insights.append(f"Peak email hours: {peak_hours}")
        
        # Subject pattern insights
        subject_patterns = patterns['subject_patterns']
        reply_ratio = subject_patterns.get('RE', 0) / max(patterns['total_emails'], 1)
        if reply_ratio > 0.3:
            insights.append(f"High reply ratio: {reply_ratio:.1%}")
        
        return insights

def main():
    import argparse
    parser = argparse.ArgumentParser(description='Email Pattern Detector')
    parser.add_argument('user_id', type=int, help='User ID to analyze')
    parser.add_argument('--days', type=int, default=30, help='Days to analyze')
    parser.add_argument('--insights', action='store_true', help='Generate insights')
    
    args = parser.parse_args()
    
    detector = PatternDetector()
    
    if args.insights:
        insights = detector.generate_pattern_insights(args.user_id)
        print("Pattern Insights:")
        for insight in insights:
            print(f"â€¢ {insight}")
    else:
        patterns = detector.detect_patterns(args.user_id, args.days)
        print(json.dumps(patterns, indent=2, default=str))

if __name__ == "__main__":
    main()
"""
        
        pattern_detector_file = intel_dir / "pattern_detector.py"
        with open(pattern_detector_file, 'w') as f:
            f.write(pattern_detector)
        
        try:
            os.chmod(pattern_detector_file, 0o755)
        except:
            pass
        
        self.analysis_results['pattern_detection'].append({
            'type': 'Email Pattern Detector',
            'file': str(pattern_detector_file),
            'features': 'Content pattern matching, timing analysis, subject pattern analysis',
            'usage': 'python pattern_detector.py user_id --insights'
        })
    
    def _create_smart_filters(self):
        """Create intelligent email filtering system"""
        print("ðŸŽ¯ Creating smart filters...")
        
        smart_filter_engine = """#!/usr/bin/env python3
\"\"\"
Smart Email Filtering Engine
Generated by Email Intelligence Agent
\"\"\"

import json
from datetime import datetime
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from backend import create_app, db
from backend.models.email import Email

class SmartFilterEngine:
    def __init__(self):
        self.app = create_app()
        self.filters = self._load_default_filters()
    
    def _load_default_filters(self) -> Dict[str, Dict]:
        \"\"\"Load default smart filters\"\"\"
        return {
            'high_priority': {
                'keywords': ['urgent', 'asap', 'critical', 'important'],
                'senders': [],  # Will be populated from VIP analysis
                'subject_patterns': [r'\\[URGENT\\]', r'\\[HIGH\\]'],
                'action': 'mark_priority_high'
            },
            'automated': {
                'sender_patterns': [r'noreply', r'no-reply', r'automated', r'notification'],
                'subject_patterns': [r'\\[automated\\]', r'system notification'],
                'action': 'mark_automated'
            },
            'newsletters': {
                'keywords': ['newsletter', 'unsubscribe', 'marketing'],
                'sender_patterns': [r'marketing@', r'news@', r'newsletter@'],
                'action': 'mark_newsletter'
            },
            'meetings': {
                'keywords': ['meeting', 'calendar', 'invite', 'conference'],
                'subject_patterns': [r'meeting', r'call', r'zoom', r'teams'],
                'action': 'mark_meeting'
            }
        }
    
    def apply_filters(self, user_id: int, email_id: int = None) -> Dict[str, Any]:
        \"\"\"Apply smart filters to emails\"\"\"
        with self.app.app_context():
            query = Email.query.filter_by(user_id=user_id)
            if email_id:
                query = query.filter_by(id=email_id)
            
            emails = query.all()
            results = {'processed': 0, 'matches': defaultdict(list)}
            
            for email in emails:
                for filter_name, filter_config in self.filters.items():
                    if self._email_matches_filter(email, filter_config):
                        results['matches'][filter_name].append(email.id)
                        self._apply_filter_action(email, filter_config['action'])
                        results['processed'] += 1
            
            db.session.commit()
            return dict(results)
    
    def _email_matches_filter(self, email: Email, filter_config: Dict) -> bool:
        \"\"\"Check if email matches filter criteria\"\"\"
        content = (email.subject + ' ' + (email.body or '')).lower()
        sender = (email.sender_email or '').lower()
        
        # Check keywords
        keywords = filter_config.get('keywords', [])
        if keywords and any(keyword in content for keyword in keywords):
            return True
        
        # Check sender patterns
        sender_patterns = filter_config.get('sender_patterns', [])
        if sender_patterns:
            import re
            for pattern in sender_patterns:
                if re.search(pattern, sender, re.IGNORECASE):
                    return True
        
        # Check subject patterns
        subject_patterns = filter_config.get('subject_patterns', [])
        if subject_patterns and email.subject:
            import re
            for pattern in subject_patterns:
                if re.search(pattern, email.subject, re.IGNORECASE):
                    return True
        
        return False
    
    def _apply_filter_action(self, email: Email, action: str):
        \"\"\"Apply filter action to email\"\"\"
        if action == 'mark_priority_high':
            # Add metadata or update email priority
            pass
        elif action == 'mark_automated':
            # Mark as automated
            pass
        # Add more actions as needed
    
    def create_custom_filter(self, name: str, config: Dict) -> bool:
        \"\"\"Create custom filter\"\"\"
        try:
            self.filters[name] = config
            self._save_filters()
            return True
        except Exception:
            return False
    
    def _save_filters(self):
        \"\"\"Save filters to file\"\"\"
        filters_file = Path(__file__).parent / 'custom_filters.json'
        with open(filters_file, 'w') as f:
            json.dump(self.filters, f, indent=2)

def main():
    import argparse
    parser = argparse.ArgumentParser(description='Smart Filter Engine')
    parser.add_argument('user_id', type=int, help='User ID')
    parser.add_argument('--apply', action='store_true', help='Apply filters')
    parser.add_argument('--email-id', type=int, help='Specific email ID')
    
    args = parser.parse_args()
    
    engine = SmartFilterEngine()
    
    if args.apply:
        results = engine.apply_filters(args.user_id, args.email_id)
        print(f"Processed: {results['processed']} emails")
        for filter_name, matches in results['matches'].items():
            print(f"{filter_name}: {len(matches)} matches")

if __name__ == "__main__":
    main()
"""
        
        smart_filter_file = intel_dir / "smart_filter.py"
        with open(smart_filter_file, 'w') as f:
            f.write(smart_filter_engine)
        
        try:
            os.chmod(smart_filter_file, 0o755)
        except:
            pass
        
        self.analysis_results['smart_filters'].append({
            'type': 'Smart Filter Engine',
            'file': str(smart_filter_file),
            'features': 'Automated classification, custom filters, priority detection',
            'usage': 'python smart_filter.py user_id --apply'
        })
    
    def _generate_productivity_insights(self):
        """Generate productivity insights"""
        print("ðŸ“Š Generating productivity insights...")
        
        productivity_analyzer = """#!/usr/bin/env python3
\"\"\"
Email Productivity Insights Generator
Generated by Email Intelligence Agent
\"\"\"

import json
from datetime import datetime, timedelta
from collections import defaultdict
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

from backend import create_app, db
from backend.models.email import Email
from backend.models.task import Task

class ProductivityAnalyzer:
    def __init__(self):
        self.app = create_app()
    
    def generate_insights(self, user_id: int, days: int = 30) -> Dict[str, Any]:
        \"\"\"Generate productivity insights\"\"\"
        with self.app.app_context():
            cutoff_date = datetime.now() - timedelta(days=days)
            
            emails = Email.query.filter(
                Email.user_id == user_id,
                Email.received_at >= cutoff_date
            ).all()
            
            tasks = Task.query.filter(
                Task.user_id == user_id,
                Task.created_at >= cutoff_date
            ).all()
            
            insights = {
                'email_volume': self._analyze_email_volume(emails),
                'task_generation': self._analyze_task_generation(emails, tasks),
                'response_patterns': self._analyze_response_patterns(emails),
                'productivity_score': self._calculate_productivity_score(emails, tasks)
            }
            
            return insights
    
    def _analyze_email_volume(self, emails: List[Email]) -> Dict[str, Any]:
        \"\"\"Analyze email volume patterns\"\"\"
        daily_counts = defaultdict(int)
        hourly_counts = defaultdict(int)
        
        for email in emails:
            if email.received_at:
                date_key = email.received_at.date().isoformat()
                daily_counts[date_key] += 1
                hourly_counts[email.received_at.hour] += 1
        
        avg_daily = sum(daily_counts.values()) / max(len(daily_counts), 1)
        peak_hour = max(hourly_counts.items(), key=lambda x: x[1])[0] if hourly_counts else 0
        
        return {
            'total_emails': len(emails),
            'average_daily': round(avg_daily, 1),
            'peak_hour': peak_hour,
            'daily_distribution': dict(daily_counts)
        }
    
    def _analyze_task_generation(self, emails: List[Email], tasks: List[Task]) -> Dict[str, Any]:
        \"\"\"Analyze task generation from emails\"\"\"
        email_to_task = {}
        for task in tasks:
            if task.email_id:
                email_to_task[task.email_id] = task
        
        task_generating_emails = len(email_to_task)
        conversion_rate = task_generating_emails / max(len(emails), 1)
        
        # Analyze task completion
        completed_tasks = sum(1 for task in tasks if task.completed)
        completion_rate = completed_tasks / max(len(tasks), 1)
        
        return {
            'total_tasks_generated': len(tasks),
            'task_generating_emails': task_generating_emails,
            'email_to_task_rate': round(conversion_rate, 3),
            'task_completion_rate': round(completion_rate, 3),
            'completed_tasks': completed_tasks
        }
    
    def _analyze_response_patterns(self, emails: List[Email]) -> Dict[str, Any]:
        \"\"\"Analyze email response patterns\"\"\"
        reply_count = sum(1 for email in emails if email.subject and email.subject.startswith(('RE:', 'Re:')))
        forward_count = sum(1 for email in emails if email.subject and email.subject.startswith(('FWD:', 'Fwd:')))
        
        return {
            'reply_emails': reply_count,
            'forwarded_emails': forward_count,
            'original_emails': len(emails) - reply_count - forward_count
        }
    
    def _calculate_productivity_score(self, emails: List[Email], tasks: List[Task]) -> float:
        \"\"\"Calculate overall productivity score\"\"\"
        if not emails:
            return 0.0
        
        # Factors contributing to productivity score
        task_rate = len(tasks) / len(emails) * 100  # Tasks per email
        completion_rate = sum(1 for task in tasks if task.completed) / max(len(tasks), 1) * 100
        
        # Simple weighted score
        score = (task_rate * 0.6 + completion_rate * 0.4)
        return min(round(score, 1), 100.0)

def main():
    import argparse
    parser = argparse.ArgumentParser(description='Productivity Insights')
    parser.add_argument('user_id', type=int, help='User ID')
    parser.add_argument('--days', type=int, default=30, help='Analysis period')
    
    args = parser.parse_args()
    
    analyzer = ProductivityAnalyzer()
    insights = analyzer.generate_insights(args.user_id, args.days)
    
    print("Productivity Insights:")
    print(f"â€¢ Total emails: {insights['email_volume']['total_emails']}")
    print(f"â€¢ Tasks generated: {insights['task_generation']['total_tasks_generated']}")
    print(f"â€¢ Email-to-task rate: {insights['task_generation']['email_to_task_rate']}")
    print(f"â€¢ Productivity score: {insights['productivity_score']}/100")

if __name__ == "__main__":
    main()
"""
        
        productivity_file = intel_dir / "productivity_analyzer.py"
        with open(productivity_file, 'w') as f:
            f.write(productivity_analyzer)
        
        try:
            os.chmod(productivity_file, 0o755)
        except:
            pass
        
        self.analysis_results['productivity_insights'].append({
            'type': 'Productivity Analyzer',
            'file': str(productivity_file),
            'features': 'Email volume analysis, task conversion rates, productivity scoring',
            'usage': 'python productivity_analyzer.py user_id --days 30'
        })
    
    def _build_categorization_system(self):
        """Build intelligent email categorization"""
        print("ðŸ“‚ Building categorization system...")
        
        # Create main orchestration script
        orchestration_script = """#!/bin/bash
# Email Intelligence Orchestration
# Generated by Email Intelligence Agent

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
BACKEND_DIR="$(dirname "$SCRIPT_DIR")"

# Colors
GREEN='\\033[0;32m'
BLUE='\\033[0;34m'
NC='\\033[0m'

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_step() {
    echo -e "${BLUE}[STEP]${NC} $1"
}

# Run complete email intelligence analysis
analyze_user() {
    local user_id=$1
    local days=${2:-30}
    
    log_info "Running complete email intelligence analysis for user $user_id"
    
    log_step "1. Analyzing sender patterns..."
    cd "$BACKEND_DIR"
    python intelligence/sender_analyzer.py "$user_id" --days "$days" --insights
    
    log_step "2. Detecting email patterns..."
    python intelligence/pattern_detector.py "$user_id" --days "$days" --insights
    
    log_step "3. Applying smart filters..."
    python intelligence/smart_filter.py "$user_id" --apply
    
    log_step "4. Generating productivity insights..."
    python intelligence/productivity_analyzer.py "$user_id" --days "$days"
    
    log_info "Email intelligence analysis complete!"
}

# Show usage
show_usage() {
    echo "Usage: $0 analyze <user_id> [days]"
    echo ""
    echo "Commands:"
    echo "  analyze <user_id> [days]  Run complete intelligence analysis"
    echo ""
    echo "Examples:"
    echo "  $0 analyze 1 30           Analyze user 1 for last 30 days"
}

# Main function
main() {
    case "${1:-help}" in
        "analyze")
            if [[ $# -lt 2 ]]; then
                log_info "Error: User ID required"
                show_usage
                exit 1
            fi
            analyze_user "$2" "${3:-30}"
            ;;
        "help"|*)
            show_usage
            ;;
    esac
}

main "$@"
"""
        
        # Create scripts directory if it doesn't exist
        scripts_dir = self.project_root / "scripts"
        scripts_dir.mkdir(exist_ok=True)
        
        orchestration_file = scripts_dir / "email_intelligence.sh"
        with open(orchestration_file, 'w') as f:
            f.write(orchestration_script)
        
        try:
            os.chmod(orchestration_file, 0o755)
        except:
            pass
        
        self.analysis_results['categorization_rules'].append({
            'type': 'Intelligence Orchestration Script',
            'file': str(orchestration_file),
            'features': 'Complete analysis pipeline, batch processing, reporting',
            'usage': './scripts/email_intelligence.sh analyze user_id [days]'
        })
    
    def _create_analysis_tools(self):
        """Create additional analysis tools"""
        print("ðŸ”§ Creating analysis tools...")
        
        # Create a summary dashboard
        dashboard_script = """#!/usr/bin/env python3
\"\"\"
Email Intelligence Dashboard
Generated by Email Intelligence Agent
\"\"\"

import json
from datetime import datetime
from pathlib import Path
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

def generate_intelligence_dashboard(user_id: int) -> str:
    \"\"\"Generate HTML dashboard\"\"\"
    
    dashboard_html = f'''
    <!DOCTYPE html>
    <html>
    <head>
        <title>Email Intelligence Dashboard - User {user_id}</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
            .dashboard {{ max-width: 1200px; margin: 0 auto; }}
            .header {{ background: #2196F3; color: white; padding: 20px; border-radius: 8px; }}
            .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }}
            .stat-card {{ background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
            .stat-value {{ font-size: 2em; font-weight: bold; color: #2196F3; }}
            .stat-label {{ color: #666; margin-top: 5px; }}
            .insights {{ background: white; padding: 20px; border-radius: 8px; margin: 20px 0; }}
            .insight-item {{ padding: 10px 0; border-bottom: 1px solid #eee; }}
            .commands {{ background: white; padding: 20px; border-radius: 8px; }}
            .command {{ background: #f8f8f8; padding: 10px; border-radius: 4px; margin: 10px 0; font-family: monospace; }}
        </style>
    </head>
    <body>
        <div class="dashboard">
            <div class="header">
                <h1>ðŸ§  Email Intelligence Dashboard</h1>
                <p>User {user_id} - Generated on {datetime.now().strftime('%Y-%m-%d %H:%M')}</p>
            </div>
            
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-value" id="email-count">---</div>
                    <div class="stat-label">Total Emails Analyzed</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value" id="task-rate">---</div>
                    <div class="stat-label">Email-to-Task Rate</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value" id="productivity-score">---</div>
                    <div class="stat-label">Productivity Score</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value" id="vip-senders">---</div>
                    <div class="stat-label">VIP Senders</div>
                </div>
            </div>
            
            <div class="insights">
                <h2>Key Insights</h2>
                <div id="insights-list">
                    <div class="insight-item">ðŸ“§ Run analysis to generate insights</div>
                </div>
            </div>
            
            <div class="commands">
                <h2>Analysis Commands</h2>
                <div class="command">./scripts/email_intelligence.sh analyze {user_id}</div>
                <div class="command">python intelligence/sender_analyzer.py {user_id} --insights</div>
                <div class="command">python intelligence/pattern_detector.py {user_id} --insights</div>
                <div class="command">python intelligence/productivity_analyzer.py {user_id}</div>
            </div>
        </div>
    </body>
    </html>
    '''
    
    return dashboard_html

def main():
    import argparse
    parser = argparse.ArgumentParser(description='Intelligence Dashboard Generator')
    parser.add_argument('user_id', type=int, help='User ID')
    
    args = parser.parse_args()
    
    dashboard_html = generate_intelligence_dashboard(args.user_id)
    
    # Save dashboard
    dashboard_file = Path(__file__).parent.parent.parent / f'email_intelligence_dashboard_{args.user_id}.html'
    with open(dashboard_file, 'w') as f:
        f.write(dashboard_html)
    
    print(f"Dashboard generated: {dashboard_file}")

if __name__ == "__main__":
    main()
"""
        
        dashboard_file = intel_dir / "dashboard_generator.py"
        with open(dashboard_file, 'w') as f:
            f.write(dashboard_script)
        
        try:
            os.chmod(dashboard_file, 0o755)
        except:
            pass
    
    def _create_recommendation_engine(self):
        """Create recommendation engine"""
        print("ðŸ’¡ Creating recommendation engine...")
        # Simple recommendation engine implementation would go here
        pass
    
    def _generate_intelligence_report(self) -> Dict[str, Any]:
        """Generate comprehensive intelligence report"""
        
        total_tools = sum(len(tools) for tools in self.analysis_results.values())
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'project': 'Email Task Manager',
            'intelligence_summary': {
                'total_tools': total_tools,
                'sender_analysis': len(self.analysis_results['sender_analysis']),
                'pattern_detection': len(self.analysis_results['pattern_detection']),
                'smart_filters': len(self.analysis_results['smart_filters']),
                'productivity_insights': len(self.analysis_results['productivity_insights']),
                'categorization_rules': len(self.analysis_results['categorization_rules'])
            },
            'intelligence_components': self.analysis_results,
            'key_features': [
                "ðŸ‘¤ Sender behavior analysis and VIP detection",
                "ðŸ” Email pattern recognition and classification", 
                "ðŸŽ¯ Smart filtering with automated categorization",
                "ðŸ“Š Productivity insights and scoring",
                "ðŸ§  Machine learning-ready pattern extraction",
                "ðŸ“ˆ Trend analysis and usage patterns",
                "ðŸš€ Orchestrated analysis pipeline"
            ],
            'usage_examples': [
                "./scripts/email_intelligence.sh analyze 1 30",
                "python intelligence/sender_analyzer.py 1 --insights",
                "python intelligence/pattern_detector.py 1 --insights",
                "python intelligence/productivity_analyzer.py 1",
                "python intelligence/dashboard_generator.py 1"
            ]
        }
        
        # Save report
        report_file = self.project_root / "email_intelligence_report.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"\nðŸ§  Email Intelligence Setup Complete!")
        print(f"Total Tools: {total_tools}")
        print(f"Report saved to: {report_file}")
        
        return report


def main():
    """Main execution function"""
    import sys
    
    project_root = sys.argv[1] if len(sys.argv) > 1 else os.getcwd()
    
    analyzer = EmailTaskIntelligenceEngine(project_root)
    report = analyzer.run_complete_analysis()
    
    # Print summary
    print(f"\n{'='*60}")
    print(f"EMAIL INTELLIGENCE SETUP SUMMARY")
    print(f"{'='*60}")
    print(f"Total Tools: {report['intelligence_summary']['total_tools']}")
    print(f"Sender Analysis: {report['intelligence_summary']['sender_analysis']}")
    print(f"Pattern Detection: {report['intelligence_summary']['pattern_detection']}")
    print(f"Smart Filters: {report['intelligence_summary']['smart_filters']}")
    print(f"Productivity Insights: {report['intelligence_summary']['productivity_insights']}")
    print(f"Analysis Pipeline: {report['intelligence_summary']['categorization_rules']}")
    
    return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)